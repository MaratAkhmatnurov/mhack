{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "print sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "путь к тестовому файлу ожидаю здесь. Ожидаю что там будет аналогчный трейну CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "testFilePath = 'X_train-0.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, SGDRegressor\n",
    "from sklearn.svm import LinearSVC, LinearSVR\n",
    "\n",
    "from catboost import Pool, CatBoostRegressor\n",
    "\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "import time\n",
    "import cPickle as pickle\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "import re\n",
    "\n",
    "mystem = Mystem()\n",
    "modifiers = \"\\xcc\\x81|<OTHER>|<MODIFIERS>\"\n",
    "\n",
    "random_seed = int(time.time())\n",
    "print random_seed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### поднятие модели\n",
    "\n",
    "да, некрасиво, но когда времени по часу вечером не до красоты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!wget https://www.dropbox.com/s/k365es9eghn6ep8/MODEL.pcl?dl=0 > MODEL.pcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('MODEL.pcl', ) as dumpFile:\n",
    "    combinedModel = pickle.load(dumpFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "defaultModel = combinedModel[0]\n",
    "positiveModel = combinedModel[1]\n",
    "negativeModel = combinedModel[2]\n",
    "commonModel = combinedModel[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "defaultMeanLR = combinedModel[4]\n",
    "defaultNormalizedLR = combinedModel[5]\n",
    "positiveMeanLR = combinedModel[6]\n",
    "positiveNormalizedLR = combinedModel[7]\n",
    "negativeMeanLR = combinedModel[8]\n",
    "negativeNormalizedLR = combinedModel[9]\n",
    "commonMeanLR = combinedModel[10]\n",
    "commonNormalizedLR = combinedModel[11]\n",
    "concatMeanLR = combinedModel[12]\n",
    "concatNormalizedLR = combinedModel[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "defaultMeanSGD = combinedModel[14]\n",
    "defaultNormalizedSGD = combinedModel[15]\n",
    "positiveMeanSGD = combinedModel[16]\n",
    "positiveNormalizedSGD = combinedModel[17]\n",
    "negativeMeanSGD = combinedModel[18]\n",
    "negativeNormalizedSGD = combinedModel[19]\n",
    "commonMeanSGD = combinedModel[20]\n",
    "commonNormalizedSGD = combinedModel[21]\n",
    "concatMeanSGD = combinedModel[22]\n",
    "concatNormalizedSGD = combinedModel[23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "defaultMeanSVMR = combinedModel[24]\n",
    "defaultNormalizedSVMR = combinedModel[25]\n",
    "positiveMeanSVMR = combinedModel[26]\n",
    "positiveNormalizedSVMR = combinedModel[27]\n",
    "negativeMeanSVMR = combinedModel[28]\n",
    "negativeNormalizedSVMR = combinedModel[29]\n",
    "commonMeanSVMR = combinedModel[30]\n",
    "commonNormalizedSVMR = combinedModel[31]\n",
    "concatMeanSVMR = combinedModel[32]\n",
    "concatNormalizedSVMR = combinedModel[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "defaultMeanSVMC = combinedModel[34]\n",
    "defaultNormalizedSVMC = combinedModel[35]\n",
    "positiveMeanSVMC = combinedModel[36]\n",
    "positiveNormalizedSVMC = combinedModel[37]\n",
    "negativeMeanSVMC = combinedModel[38]\n",
    "negativeNormalizedSVMC = combinedModel[39]\n",
    "commonMeanSVMC = combinedModel[40]\n",
    "commonNormalizedSVMC = combinedModel[41]\n",
    "concatMeanSVMC = combinedModel[42]\n",
    "concatNormalizedSVMC = combinedModel[43]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_std_default = combinedModel[44]\n",
    "mean_std_default_2 = combinedModel[45]\n",
    "mean_std_u_default = combinedModel[46]\n",
    "mean_std_u_default_2 = combinedModel[47]\n",
    "mean_std_common = combinedModel[48]\n",
    "mean_std_common_2 = combinedModel[49]\n",
    "mean_std_u_common = combinedModel[50]\n",
    "mean_std_u_common_2 = combinedModel[51]\n",
    "mean_std_pos = combinedModel[52]\n",
    "mean_std_pos_2 = combinedModel[53]\n",
    "mean_std_u_pos = combinedModel[54]\n",
    "mean_std_u_pos_2 = combinedModel[55]\n",
    "mean_std_neg = combinedModel[56]\n",
    "mean_std_neg_2 = combinedModel[57]\n",
    "mean_std_u_neg = combinedModel[58]\n",
    "mean_std_u_neg_2 = combinedModel[59]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_std_default_hq = combinedModel[60]\n",
    "mean_std_default_shq = combinedModel[61]\n",
    "mean_std_u_default_hq = combinedModel[62]\n",
    "mean_std_u_default_shq = combinedModel[63]\n",
    "mean_std_common_hq = combinedModel[64]\n",
    "mean_std_common_shq = combinedModel[65]\n",
    "mean_std_u_common_hq = combinedModel[66]\n",
    "mean_std_u_common_shq = combinedModel[67]\n",
    "mean_std_pos_hq = combinedModel[68]\n",
    "mean_std_pos_shq = combinedModel[69]\n",
    "mean_std_u_pos_hq = combinedModel[70]\n",
    "mean_std_u_pos_shq = combinedModel[71]\n",
    "mean_std_neg_hq = combinedModel[72]\n",
    "mean_std_neg_shq = combinedModel[73]\n",
    "mean_std_u_neg_hq = combinedModel[74]\n",
    "mean_std_u_neg_shq = combinedModel[75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "catBoost = combinedModel[76]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Применение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(testFilePath, ',')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simplify_comment(comment):\n",
    "    if comment is nan:\n",
    "        return None\n",
    "    lemmas = mystem.lemmatize(comment)\n",
    "    lemmas = filter(lambda x: not x.isspace(), lemmas)\n",
    "    if len(lemmas) == 0:\n",
    "        #print comment\n",
    "        return None\n",
    "    ne_lemmas = []\n",
    "    for i in xrange(0, len(lemmas)):\n",
    "        if lemmas[i-1] == 'не':\n",
    "            ne_lemmas[-1] = 'не_' + lemmas[i]\n",
    "        else:\n",
    "            ne_lemmas.append(lemmas[i])\n",
    "    return ne_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_vector(comment, model):\n",
    "    if comment is NaN:\n",
    "        return (np.zeros(100), np.zeros(100), np.zeros(100))\n",
    "    simple = simplify_comment(comment)\n",
    "    vector = np.zeros(100)\n",
    "    count = 0;\n",
    "    for word in simple:\n",
    "        if word in model:\n",
    "            vector += model[word]\n",
    "            count += 1\n",
    "    if count == 0:\n",
    "        return (np.zeros(100), np.zeros(100), np.zeros(100))\n",
    "    mean = vector / count\n",
    "    normalized = vector / np.linalg.norm(vector)\n",
    "    return vector, mean, normalized\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "defaultVectorsTest = []\n",
    "positiveVectorsTest = []\n",
    "negativeVectorsTest = []\n",
    "commonVectorsTest = []\n",
    "\n",
    "defaultVectorsTestMean = []\n",
    "positiveVectorsTestMean = []\n",
    "negativeVectorsTestMean = []\n",
    "commonVectorsTestMean = []\n",
    "\n",
    "defaultVectorsTestNormalized = []\n",
    "positiveVectorsTestNormalized = []\n",
    "negativeVectorsTestNormalized = []\n",
    "commonVectorsTestNormalized = []\n",
    "\n",
    "for opinion in data.itertuples(index=True, name='Opinion'):\n",
    "    comments = []\n",
    "    comment = opinion.comment\n",
    "    vectors = get_vector(comment, defaultModel)\n",
    "    defaultVectorsTest.append(vectors[0])\n",
    "    defaultVectorsTestMean.append(vectors[1])\n",
    "    defaultVectorsTestNormalized.append(vectors[2])\n",
    "    comments.append('' if opinion.comment is NaN else opinion.comment)\n",
    "    \n",
    "    comment = opinion.commentPositive\n",
    "    vectors = get_vector(comment, positiveModel)\n",
    "    positiveVectorsTest.append(vectors[0])\n",
    "    positiveVectorsTestMean.append(vectors[1])\n",
    "    positiveVectorsTestNormalized.append(vectors[2])\n",
    "    comments.append('' if opinion.commentPositive is NaN else opinion.commentPositive)\n",
    "\n",
    "    comment = opinion.commentNegative\n",
    "    vectors = get_vector(comment, negativeModel)\n",
    "    negativeVectorsTest.append(vectors[0])\n",
    "    negativeVectorsTestMean.append(vectors[1])\n",
    "    negativeVectorsTestNormalized.append(vectors[2])\n",
    "    comments.append('' if opinion.commentNegative is NaN else opinion.commentNegative)\n",
    "\n",
    "    comment = ' '.join(comments)\n",
    "    vectors = get_vector(comment, commonModel)\n",
    "    commonVectorsTest.append(vectors[0])\n",
    "    commonVectorsTestMean.append(vectors[1])\n",
    "    commonVectorsTestNormalized.append(vectors[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "defaultVectorsTest = np.array(defaultVectorsTest)\n",
    "defaultVectorsTestMean = np.array(defaultVectorsTestMean)\n",
    "defaultVectorsTestNormalized = np.array(defaultVectorsTestNormalized)\n",
    "commonVectorsTest = np.array(commonVectorsTest)\n",
    "commonVectorsTestMean = np.array(commonVectorsTestMean)\n",
    "commonVectorsTestNormalized = np.array(commonVectorsTestNormalized)\n",
    "positiveVectorsTest = np.array(positiveVectorsTest)\n",
    "positiveVectorsTestMean = np.array(positiveVectorsTestMean)\n",
    "positiveVectorsTestNormalized = np.array(positiveVectorsTestNormalized)\n",
    "negativeVectorsTest = np.array(negativeVectorsTest)\n",
    "negativeVectorsTestMean = np.array(negativeVectorsTestMean)\n",
    "negativeVectorsTestNormalized = np.array(negativeVectorsTestNormalized)\n",
    "\n",
    "vectorsTest = np.hstack((defaultVectorsTest, positiveVectorsTest, negativeVectorsTest, commonVectorsTest))\n",
    "vectorsTestMean = np.hstack((defaultVectorsTestMean, positiveVectorsTestMean, negativeVectorsTestMean, commonVectorsTestMean))\n",
    "vectorsTestNormalized = np.hstack((defaultVectorsTestNormalized, positiveVectorsTestNormalized, negativeVectorsTestNormalized, commonVectorsTestNormalized))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "testLM = np.vstack(( defaultMeanLR.predict(defaultVectorsTestMean),\n",
    "                     defaultNormalizedLR.predict(defaultVectorsTestNormalized),\n",
    "                     defaultMeanSVMC.predict(defaultVectorsTestMean),\n",
    "                     defaultNormalizedSVMC.predict(defaultVectorsTestNormalized),\n",
    "                     positiveMeanLR.predict(positiveVectorsTestMean),\n",
    "                     positiveNormalizedLR.predict(positiveVectorsTestNormalized),\n",
    "                     positiveMeanSVMC.predict(positiveVectorsTestMean),\n",
    "                     positiveNormalizedSVMC.predict(positiveVectorsTestNormalized),\n",
    "                     negativeMeanLR.predict(negativeVectorsTestMean),\n",
    "                     negativeNormalizedLR.predict(negativeVectorsTestNormalized),\n",
    "                     negativeMeanSVMC.predict(negativeVectorsTestMean),\n",
    "                     negativeNormalizedSVMC.predict(negativeVectorsTestNormalized),\n",
    "                     commonMeanLR.predict(commonVectorsTestMean),\n",
    "                     commonNormalizedLR.predict(commonVectorsTestNormalized),\n",
    "                     commonMeanSVMC.predict(commonVectorsTestMean),\n",
    "                     commonNormalizedSVMC.predict(commonVectorsTestNormalized),\n",
    "                     concatMeanLR.predict(vectorsTestMean),\n",
    "                     concatNormalizedLR.predict(vectorsTestNormalized),\n",
    "                     concatMeanSVMC.predict(vectorsTestMean),\n",
    "                     concatNormalizedSVMC.predict(vectorsTestNormalized),\n",
    "                     concatMeanSVMR.predict(vectorsTestMean),\n",
    "                     concatNormalizedSVMR.predict(vectorsTestNormalized),\n",
    "                     concatMeanSGD.predict(vectorsTestMean),\n",
    "                     concatNormalizedSGD.predict(vectorsTestNormalized),\n",
    "                     commonMeanSVMR.predict(commonVectorsTestMean),\n",
    "                     commonNormalizedSVMR.predict(commonVectorsTestNormalized),\n",
    "                     commonMeanSGD.predict(commonVectorsTestMean),\n",
    "                     commonNormalizedSGD.predict(commonVectorsTestNormalized),\n",
    "                     negativeMeanSVMR.predict(negativeVectorsTestMean),\n",
    "                     negativeNormalizedSVMR.predict(negativeVectorsTestNormalized),\n",
    "                     negativeMeanSGD.predict(negativeVectorsTestMean),\n",
    "                     negativeNormalizedSGD.predict(negativeVectorsTestNormalized),\n",
    "                     positiveMeanSVMR.predict(positiveVectorsTestMean),\n",
    "                     positiveNormalizedSVMR.predict(positiveVectorsTestNormalized),\n",
    "                     positiveMeanSGD.predict(positiveVectorsTestMean),\n",
    "                     positiveNormalizedSGD.predict(positiveVectorsTestNormalized),\n",
    "                     defaultMeanSVMR.predict(defaultVectorsTestMean),\n",
    "                     defaultNormalizedSVMR.predict(defaultVectorsTestNormalized),\n",
    "                     defaultMeanSGD.predict(defaultVectorsTestMean),\n",
    "                     defaultNormalizedSGD.predict(defaultVectorsTestNormalized))).T\n",
    "\n",
    "testLM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pronoun = 'я что он как этот они мы весь который она так свой вы ты такой его себя ее когда вот другой наш самый мой кто сам там какой их потом ничто каждый потому тогда здесь какой-то что-то всегда ваш никто почему поэтому свое никогда никакой некоторый твой куда кто-то как-то зачем сей туда какой-нибудь всего откуда сюда столь где-то что-нибудь почему-то некий когда-то чего отсюда чей нечто кто-нибудь вон оттуда какой-либо таков куда-то никуда каков таковой кой оттого некогда отчего нигде кое-что когда-нибудь чей-то где-нибудь такой-то что-либо всюду как-нибудь откуда-то ничуть куда-нибудь сколь тут-то этакий тот-то так-то кое-какой кое-как кое-кто зачем-то кое-где кто-либо ихний некто отчего-то каковой эдакий нибудь тогда-то чего-то когда-либо почем отовсюду ничей доселе оный ниоткуда экий чей-нибудь сям никой'.split()\n",
    "preposition = 'а-ля без безо благодаря близ в вблизи ввиду вглубь вдогон вдоль взамен включая вкруг вместо вне внизу внутри внутрь во возле вокруг вопреки вослед впереди вразрез вроде вслед вследствие для для-ради до за заместо из из-за из-под изнутри изо к касательно ко кроме кругом меж между мимо на наверху навстречу над надо назад накануне наперекор наперерез наподобие напротив насупротив насчёт ниже о об обо обок около окрест окромя округ опосля от относительно ото перед передо по по-за по-над по-под поверх под подле подо подобно позади позднее помимо поперёк порядка посередине посередь после посреди посредине посредством пред предо прежде при про против путём ради с сверх сверху свыше сзади сквозь снизу со согласно спустя среди средь сродни супротив через чрез'.split()\n",
    "pronoun = set(pronoun)\n",
    "preposition = set(preposition)\n",
    "len(pronoun), len(preposition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lemma_filter(x):\n",
    "    ux = unicode(x,\"utf8\")\n",
    "    return ux.isalpha() \\\n",
    "        and x not in pronoun \\\n",
    "        and x not in preposition\n",
    "\n",
    "def process_comment(comment, rate, dictionary, u_dictionary):\n",
    "    if comment is nan:\n",
    "        return\n",
    "    lemmas = mystem.lemmatize(comment)\n",
    "    lemmas = filter(lemma_filter, lemmas)\n",
    "    if len(lemmas) == 0:\n",
    "        #print comment\n",
    "        return\n",
    "    ne_lemmas = []\n",
    "    for i in xrange(0, len(lemmas)):\n",
    "        if lemmas[i-1] == 'не':\n",
    "            ne_lemmas.append('не_' + lemmas[i])\n",
    "        elif len(unicode(lemmas[i],\"utf8\")) > 2:\n",
    "            ne_lemmas.append(lemmas[i])\n",
    "            \n",
    "    for lemma in ne_lemmas:\n",
    "        dictionary[lemma].append(rate)\n",
    "        lemma_common_rates[lemma].append(rate)\n",
    "    for lemma in set(ne_lemmas):\n",
    "        u_dictionary[lemma].append(rate)\n",
    "        u_lemma_common_rates[lemma].append(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_mean(comment, mean, std=defaultdict(float), default_value=-1000., unique=False):\n",
    "    if comment is nan:\n",
    "        return default_value\n",
    "    lemmas = mystem.lemmatize(comment)\n",
    "    lemmas = filter(lemma_filter, lemmas)\n",
    "    if len(lemmas) == 0:\n",
    "        return default_value\n",
    "    ne_lemmas = []\n",
    "    if lemmas[0] != 'не':\n",
    "        ne_lemmas.append(lemmas[0])\n",
    "    for i in xrange(1, len(lemmas)):\n",
    "        if lemmas[i-1] == 'не':\n",
    "            ne_lemmas.append('не_' + lemmas[i])\n",
    "        elif len(unicode(lemmas[i],\"utf8\")) > 2:\n",
    "            ne_lemmas.append(lemmas[i])\n",
    "    means = []\n",
    "    stds = []\n",
    "    if unique:\n",
    "        ne_lemmas = set(ne_lemmas)\n",
    "    for lemma in ne_lemmas:\n",
    "        if lemma not in mean:\n",
    "            continue\n",
    "        means.append(mean[lemma])\n",
    "        stds.append(std[lemma])\n",
    "    if len(means) == 0:\n",
    "        return default_value\n",
    "    lemma_scores = np.random.normal(means, stds)\n",
    "    prediction = np.mean(lemma_scores)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rates = np.array([1.0, 1.3, 1.7])\n",
    "rates = np.hstack((rates, rates + 1, rates + 2, rates + 3, [5]))\n",
    "def discr(prediction):\n",
    "    return rates[np.argmin(np.abs(rates - prediction))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_discr_with_hq_dict(comment, mean, std=defaultdict(float), unique=False):\n",
    "    if comment is nan:\n",
    "        return 0\n",
    "    lemmas = mystem.lemmatize(comment)\n",
    "    lemmas = filter(lemma_filter, lemmas)\n",
    "    if len(lemmas) == 0:\n",
    "        return 0\n",
    "    ne_lemmas = []\n",
    "    if lemmas[0] != 'не':\n",
    "        ne_lemmas.append(lemmas[0])\n",
    "    for i in xrange(1, len(lemmas)):\n",
    "        if lemmas[i-1] == 'не':\n",
    "            ne_lemmas.append('не_' + lemmas[i])\n",
    "        elif len(unicode(lemmas[i],\"utf8\")) > 2:\n",
    "            ne_lemmas.append(lemmas[i])\n",
    "    means = []\n",
    "    stds = []\n",
    "    if unique:\n",
    "        ne_lemmas = set(ne_lemmas)\n",
    "    for lemma in ne_lemmas:\n",
    "        if lemma not in mean:\n",
    "            continue\n",
    "        means.append(mean[lemma])\n",
    "        stds.append(std[lemma])\n",
    "    if len(means) == 0:\n",
    "        return 0\n",
    "    lemma_scores = np.random.normal(means, stds)\n",
    "    prediction = np.mean(lemma_scores)\n",
    "    return int(discr(prediction) * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "describe_rate = {\n",
    "    5: ['5 балл', 'пять балл', 'оценка 5', 'оценка пять', 'оценка  -  5', 'оценка  -  пять', 'ставить 5', 'ставить пять', 'пятерка', 'пятерочка'],\n",
    "    4: ['4 балл', 'четыре балл', 'оценка 4', 'оценка четыре', 'оценка  -  4', 'оценка  -  четыре', 'ставить 4', 'ставить четыре', 'четверка', 'четверочка'],\n",
    "    3: ['3 балл', 'три балл', 'оценка 3', 'оценка три', 'оценка  -  3', 'оценка  -  три', 'ставить 3', 'ставить три', ' тройка ', 'троечка'],\n",
    "    2: ['2 балл', 'два балл', 'оценка 2', 'оценка два', 'оценка  -  2', 'оценка  -  два', 'ставить 2', 'ставить два', 'двойка', 'двоечка'],\n",
    "    1: ['1 балл', 'оценка 1', 'оценка один', 'оценка  -  1', 'оценка  -  один', 'ставить 1', 'ставить один', 'единица'],\n",
    "}\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "def find_description(comment):\n",
    "    if comment is NaN:\n",
    "        return 0\n",
    "    lemmas = mystem.lemmatize(comment)\n",
    "    lemmas = filter(lambda x: not x.isspace(), lemmas)\n",
    "    normalized_comment = ' '.join(lemmas)\n",
    "    r = []\n",
    "    for rate, describes in describe_rate.iteritems():\n",
    "        for describe in describes:\n",
    "            if normalized_comment.find(describe) == -1:\n",
    "                continue\n",
    "            r.append(rate)\n",
    "    if len(r) == 0:\n",
    "        return 0\n",
    "    return Counter(r).most_common()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features(pandas_dataset, linearModelPredictions, w2v):\n",
    "    assert len(pandas_dataset) == len(linearModelPredictions)\n",
    "    pool = []\n",
    "    lm_index = 0\n",
    "    for opinion in pandas_dataset.itertuples(index=True, name='Opinion'):\n",
    "        features = []\n",
    "\n",
    "        # 0 sku\n",
    "        features.append(opinion.sku)\n",
    "        # 1 brandId\n",
    "        features.append(opinion.brandId)\n",
    "        # 2 cat1\n",
    "        features.append(opinion.categoryLevel1Id)\n",
    "        # 3 cat2\n",
    "        features.append(opinion.categoryLevel2Id)\n",
    "\n",
    "        # 4 comment\n",
    "        if (opinion.comment is NaN) or len(opinion.comment.split()) < 5:\n",
    "            features.append(\"NO\")\n",
    "        else:\n",
    "            features.append(\"YES\")\n",
    "        # 5 positiveComment\n",
    "        if (opinion.commentPositive is NaN) or len(opinion.commentPositive.split()) < 5:\n",
    "            features.append(\"NO\")\n",
    "        else:\n",
    "            features.append(\"YES\")\n",
    "        # 6 negativeComment\n",
    "        if (opinion.commentNegative is NaN) or len(opinion.commentNegative.split()) < 5:\n",
    "            features.append(\"NO\")\n",
    "        else:\n",
    "            features.append(\"YES\")\n",
    "\n",
    "        # 7 description\n",
    "        features.append(find_description(opinion.comment))\n",
    "\n",
    "        # 8 defaultDict_strong\n",
    "        features.append(predict_mean(opinion.comment, mean_std_default[0]))\n",
    "        # 9 defaultDict_strong_unique\n",
    "        features.append(predict_mean(opinion.comment, mean_std_u_default[0], unique=True))\n",
    "\n",
    "        # 10 defaultDict2_strong\n",
    "        features.append(predict_mean(opinion.comment, mean_std_default_2[0]))\n",
    "        # 11 defaultDict2_strong_unique\n",
    "        features.append(predict_mean(opinion.comment, mean_std_u_default_2[0], unique=True))\n",
    "\n",
    "        # 12 defaultDict_discr_hq_strong\n",
    "        features.append(predict_discr_with_hq_dict(opinion.comment, mean_std_default_hq[0]))\n",
    "        # 13 defaultDict_hq_discr_strong_unique\n",
    "        features.append(predict_discr_with_hq_dict(opinion.comment, mean_std_u_default_hq[0], unique=True))\n",
    "        \n",
    "        # 14 defaultDict_discr_shq_strong\n",
    "        features.append(predict_discr_with_hq_dict(opinion.comment, mean_std_default_shq[0]))\n",
    "        # 15 defaultDict_discr_shq_strong_unique\n",
    "        features.append(predict_discr_with_hq_dict(opinion.comment, mean_std_u_default_shq[0], unique=True))\n",
    "        \n",
    "        # 16 posDict_strong\n",
    "        features.append(predict_mean(opinion.commentPositive, mean_std_pos[0]))\n",
    "        # 17 posDict_strong_unique\n",
    "        features.append(predict_mean(opinion.commentPositive, mean_std_u_pos[0], unique=True))\n",
    "        \n",
    "        # 18 posDict2_strong\n",
    "        features.append(predict_mean(opinion.commentPositive, mean_std_pos_2[0]))\n",
    "        # 19 posDict2_strong_unique\n",
    "        features.append(predict_mean(opinion.commentPositive, mean_std_u_pos_2[0], unique=True))\n",
    "        \n",
    "        # 20 posDict_discr_hq_strong\n",
    "        features.append(predict_discr_with_hq_dict(opinion.commentPositive, mean_std_pos_hq[0]))\n",
    "        # 21 posDict_discr_hq_strong_unique\n",
    "        features.append(predict_discr_with_hq_dict(opinion.commentPositive, mean_std_u_pos_hq[0], unique=True))\n",
    "    \n",
    "        # 22 posDict_discr_shq_strong\n",
    "        features.append(predict_discr_with_hq_dict(opinion.commentPositive, mean_std_pos_shq[0]))\n",
    "        # 23 posDict_shq_discr_strong_unique\n",
    "        features.append(predict_discr_with_hq_dict(opinion.commentPositive, mean_std_u_pos_shq[0], unique=True))\n",
    "        \n",
    "        # 24 negDict_strong\n",
    "        features.append(predict_mean(opinion.commentNegative, mean_std_neg[0]))\n",
    "        # 25 negDict_strong_unique\n",
    "        features.append(predict_mean(opinion.commentNegative, mean_std_u_neg[0], unique=True))\n",
    "        \n",
    "        # 26 negDict2_strong\n",
    "        features.append(predict_mean(opinion.commentNegative, mean_std_neg_2[0]))\n",
    "        # 27 negDict2_strong_unique\n",
    "        features.append(predict_mean(opinion.commentNegative, mean_std_u_neg_2[0], unique=True))\n",
    "        \n",
    "        # 28 negDict_discr_hq_strong\n",
    "        features.append(predict_discr_with_hq_dict(opinion.commentNegative, mean_std_neg_hq[0]))\n",
    "        # 29 negDict_discr_hq_strong_unique\n",
    "        features.append(predict_discr_with_hq_dict(opinion.commentNegative, mean_std_u_neg_hq[0], unique=True))\n",
    "        \n",
    "        # 30 negDict_discr_shq_strong\n",
    "        features.append(predict_discr_with_hq_dict(opinion.commentNegative, mean_std_neg_shq[0]))\n",
    "        # 31 negDict_discr_shq_strong_unique\n",
    "        features.append(predict_discr_with_hq_dict(opinion.commentNegative, mean_std_u_neg_shq[0], unique=True))\n",
    "        \n",
    "        comment = [opinion.comment,\n",
    "                   '' if opinion.commentPositive is NaN else opinion.commentPositive,\n",
    "                   '' if opinion.commentNegative is NaN else opinion.commentNegative]\n",
    "        comment = ' '.join(comment)\n",
    "\n",
    "        # 32 commonDict_strong\n",
    "        features.append(predict_mean(comment, mean_std_common[0]))\n",
    "        # 33 commonDict_strong_unique\n",
    "        features.append(predict_mean(comment, mean_std_u_common[0], unique=True))\n",
    "        \n",
    "        # 34 commonDict2_strong\n",
    "        features.append(predict_mean(comment, mean_std_common_2[0]))\n",
    "        # 35 commonDict2_strong_unique\n",
    "        features.append(predict_mean(comment, mean_std_u_common_2[0], unique=True))\n",
    "        \n",
    "        # 36 commonDict_discr_hq_strong\n",
    "        features.append(predict_discr_with_hq_dict(comment, mean_std_common_hq[0]))\n",
    "        # 37 commonDict_discr_hq_strong_unique\n",
    "        features.append(predict_discr_with_hq_dict(comment, mean_std_u_common_hq[0], unique=True))\n",
    "        \n",
    "        # 38 commonDict_discr_shq_strong\n",
    "        features.append(predict_discr_with_hq_dict(comment, mean_std_common_shq[0]))\n",
    "        # 39 commonDict_discr_shq_strong_unique\n",
    "        features.append(predict_discr_with_hq_dict(comment, mean_std_u_common_shq[0], unique=True))\n",
    "        \n",
    "        # 40 - 79 Linear model predictions\n",
    "        features = features + linearModelPredictions[lm_index]\n",
    "        \n",
    "        # 80 ... vectors\n",
    "        features = features + w2v[lm_index]\n",
    "        \n",
    "        for i in xrange(40, 60):\n",
    "            features[i] = int(features[i])\n",
    "        lm_index += 1\n",
    "        pool.append(features)\n",
    "    return pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_names = [\n",
    "    \"sku\",\n",
    "    \"brandId\",\n",
    "    \"cat1\",\n",
    "    \"cat2\",\n",
    "    \"comment\",\n",
    "    \"positiveComment\",\n",
    "    \"negativeComment\",\n",
    "    \"description\",\n",
    "    \"defaultDict_strong\",\n",
    "    \"defaultDict_strong_unique\",\n",
    "    \"defaultDict2_strong\",\n",
    "    \"defaultDict2_strong_unique\",\n",
    "    \"defaultDict_discr_hq_strong\",\n",
    "    \"defaultDict_discr_hq_strong_unique\",\n",
    "    \"defaultDict_discr_shq_strong\",\n",
    "    \"defaultDict_discr_shq_strong_unique\",\n",
    "    \"posDict_strong\",\n",
    "    \"posDict_strong_unique\",\n",
    "    \"posDict2_strong\",\n",
    "    \"posDict2_strong_unique\",\n",
    "    \"posDict_discr_hq_strong\",\n",
    "    \"posDict_discr_hq_strong_unique\",\n",
    "    \"posDict_discr_shq_strong\",\n",
    "    \"posDict_discr_shq_strong_unique\",\n",
    "    \"negDict_strong\",\n",
    "    \"negDict_strong_unique\",\n",
    "    \"negDict2_strong\",\n",
    "    \"negDict2_strong_unique\",\n",
    "    \"negDict_discr_hq_strong\",\n",
    "    \"negDict_discr_hq_strong_unique\",\n",
    "    \"negDict_discr_shq_strong\",\n",
    "    \"negDict_discr_shq_strong_unique\",\n",
    "    \"commonDict_strong\",\n",
    "    \"commonDict_strong_unique\",\n",
    "    \"commonDict2_strong\",\n",
    "    \"commonDict2_strong_unique\",\n",
    "    \"commonDict_discr_hq_strong\",\n",
    "    \"commonDict_discr_hq_strong_unique\",\n",
    "    \"commonDict_discr_shq_strong\",\n",
    "    \"commonDict_discr_shq_strong_unique\",\n",
    "    \n",
    "    'defaultMeanLR',\n",
    "    'defaultNormalizedLR',\n",
    "    'defaultMeanSVMC',\n",
    "    'defaultNormalizedSVMC',\n",
    "    'positiveMeanLR',\n",
    "    'positiveNormalizedLR',\n",
    "    'positiveMeanSVMC',\n",
    "    'positiveNormalizedSVMC',\n",
    "    'negativeMeanLR',\n",
    "    'negativeNormalizedLR',\n",
    "    'negativeMeanSVMC',\n",
    "    'negativeNormalizedSVMC',\n",
    "    'commonMeanLR',\n",
    "    'commonNormalizedLR',\n",
    "    'commonMeanSVMC',\n",
    "    'commonNormalizedSVMC',\n",
    "    'concatMeanLR',\n",
    "    'concatNormalizedLR',\n",
    "    'concatMeanSVMC',\n",
    "    'concatNormalizedSVMC',\n",
    "\n",
    "    'concatMeanSVMR',\n",
    "    'concatNormalizedSVMR',\n",
    "    'concatMeanSGD',\n",
    "    'concatNormalizedSGD',\n",
    "    'commonMeanSVMR',\n",
    "    'commonNormalizedSVMR',\n",
    "    'commonMeanSGD',\n",
    "    'commonNormalizedSGD',\n",
    "    'negativeMeanSVMR',\n",
    "    'negativeNormalizedSVMR',\n",
    "    'negativeMeanSGD',\n",
    "    'negativeNormalizedSGD',\n",
    "    'positiveMeanSVMR',\n",
    "    'positiveNormalizedSVMR',\n",
    "    'positiveMeanSGD',\n",
    "    'positiveNormalizedSGD',\n",
    "    'defaultMeanSVMR',\n",
    "    'defaultNormalizedSVMR',\n",
    "    'defaultMeanSGD',\n",
    "    'defaultNormalizedSGD'\n",
    "]\n",
    "vector_features = ['w2v_' + str(i) for i in xrange(400)]\n",
    "feature_names = feature_names + vector_features\n",
    "cat_features = [0,1,2,3,4,5,6,7, 12,13,14,15, 20,21,22,23, 28,29,30,31, 36,37,38,39] + range(40,60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = get_features(data, testLM.tolist(), vectorsTestMean.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pool = Pool(features, cat_features=cat_features, feature_names=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# предсказания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction = catBoost.predict(pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RMSE = np.sqrt(np.mean(np.square(prediction - data.reting)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
